# Data_Analysis_Housing_Prize_Prediction

## Project Goal

This project is my first full journey into Machine Learning! The goal was simple: take a dataset of houses and build a model that could **predict their selling prices** based on features like size and amenities.

---

## Technical Stack & Flow

| Item | Role in the Project |
| :--- | :--- |
| **Language** | Python |
| **ML Model** | **ElasticNet** (a great choice for balancing complexity and performance) |
| **Key Libraries** | Pandas, NumPy, Scikit-learn |
| **Next Step** | Building a **FastAPI** service to put the model online! |

---

## Repository Structure & Project Steps

This repository is designed to be fully **reproducible**. The final model (`model.pkl`) and processed datasets are **outputs** generated by running the notebooks in order.

| File/Folder | Purpose & Role in the Pipeline |
| :--- | :--- |
| `data_analysis.ipynb` | **Step 1: Data Detective Work.** This notebook handles data loading, cleaning, **outlier detection** (like checking the 'area' feature), **Exploratory Data Analysis (EDA)**, and splitting the data into training and testing sets. |
| `modelling.ipynb` | **Step 2: Model Building.** This notebook loads the processed data, performs **model selection**, **hyperparameter tuning** for the ElasticNet model, and finally, saves the trained predictor as `model.pkl`. |

---

## How to Reproduce the Project

To recreate the model and the output files locally, you just need to run the two notebooks in order:

1.  **Clone the Repository** and ensure you have the necessary Python libraries installed (pandas, scikit-learn, etc.).
2.  **Run `data_analysis.ipynb`:** Execute all cells to prepare the data and create the splits.
3.  **Run `modelling.ipynb`:** Execute all cells to train the **ElasticNet** model and generate the final **`model.pkl`** file.
